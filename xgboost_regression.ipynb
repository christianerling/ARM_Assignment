{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from time import time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_error(actual, predicted):\n",
    "    res = np.empty(actual.shape)\n",
    "    for j in range(actual.shape[0]):\n",
    "        if actual[j] != 0:\n",
    "            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
    "        else:\n",
    "            res[j] = predicted[j] / np.mean(actual)\n",
    "    return res\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(percentage_error(np.asarray(y_true), np.asarray(y_pred)))) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate alpha score list between 0.01 and 1\n",
    "xgboost_params = {\n",
    "    'eta': [0.01, 0.015, 0.025, 0.05, 0.1],\n",
    "    'subsample': [i / 10.0 for i in range(6, 10)],\n",
    "    'colsample_bytree': [i / 10.0 for i in range(6, 10)],\n",
    "    'reg_lambda': [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 1.0],\n",
    "    'gamma': [i / 10.0 for i in range(0, 5)],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1.0],\n",
    "    'max_depth': [3, 5, 7, 9, 12, 15, 17, 25],\n",
    "    'min_child_weight': [6, 8, 10, 12],\n",
    "    'verbosity': [0]}\n",
    "data_preprocessed = pd.read_json(\"data/owi-covid-values_imputed.json\")\n",
    "x_data = data_preprocessed.loc[:, data_preprocessed.columns != \"new_deaths_smoothed\"]\n",
    "y_data = data_preprocessed.loc[:, data_preprocessed.columns == \"new_deaths_smoothed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part used for searching the hyperparameters\n",
    "t1 = time()\n",
    "# Activate with Multiprocessing, params, and 5 fold CV\n",
    "xgboost_grid_search_cv = RandomizedSearchCV(xgb.XGBRegressor(predictor=\"auto\", nthread=-1),\n",
    "                                            param_distributions=xgboost_params,\n",
    "                                            cv=5,\n",
    "                                            verbose=1, n_jobs=-1, n_iter=2000)\n",
    "xgboost_grid_search_cv.fit(x_data, y_data)\n",
    "t2 = time()\n",
    "print(\"\\n\\n\")\n",
    "print(f\"XGBoost Regression: Best Score {xgboost_grid_search_cv.best_score_}\")\n",
    "print(f\"XGBoost Regression: Best Parameter {xgboost_grid_search_cv.best_params_}\")\n",
    "print(f\"\\nExecution Time: {timedelta(seconds=(t2 - t1))}\")\n",
    "mean_times = xgboost_grid_search_cv.cv_results_[\"mean_fit_time\"]\n",
    "std_times = xgboost_grid_search_cv.cv_results_[\"std_fit_time\"]\n",
    "mean_score = xgboost_grid_search_cv.cv_results_[\"mean_test_score\"]\n",
    "std_score = xgboost_grid_search_cv.cv_results_[\"std_test_score\"]\n",
    "subsamples = np.array(xgboost_grid_search_cv.cv_results_[\"param_subsample\"], dtype=float)\n",
    "min_child_weights = np.array(xgboost_grid_search_cv.cv_results_[\"param_min_child_weight\"], dtype=float)\n",
    "max_depths = np.array(xgboost_grid_search_cv.cv_results_[\"param_max_depth\"], dtype=float)\n",
    "lambdas = np.array(xgboost_grid_search_cv.cv_results_[\"param_reg_lambda\"], dtype=float)\n",
    "gammas = np.array(xgboost_grid_search_cv.cv_results_[\"param_gamma\"], dtype=float)\n",
    "etas = np.array(xgboost_grid_search_cv.cv_results_[\"param_eta\"], dtype=float)\n",
    "colsample_bytrees = np.array(xgboost_grid_search_cv.cv_results_[\"param_colsample_bytree\"], dtype=float)\n",
    "alphas = np.array(xgboost_grid_search_cv.cv_results_[\"param_reg_alpha\"], dtype=float)\n",
    "\n",
    "grid_search_scores_xgboost = pd.DataFrame(\n",
    "    {\"mean_times\": mean_times, \"std_times\": std_times, \"mean_score\": mean_score, \"std_score\": std_score,\n",
    "     \"param_subsample\": subsamples, \"param_min_child_weight\": min_child_weights, \"param_max_depth\": max_depths,\n",
    "     \"param_lambda\": lambdas, \"param_gamma\": gammas, \"param_eta\": etas, \"colsample_bytrees\": colsample_bytrees,\n",
    "     \"param_alpha\": alphas}\n",
    ")\n",
    "grid_search_scores_xgboost.to_excel(\"data/xgboost_grid_search_results.xlsx\")\n",
    "\n",
    "grid_search_scores_xgboost = pd.read_excel(\"data/xgboost_grid_search_results.xlsx\")\n",
    "fig = make_subplots(rows=1, cols=8,\n",
    "                    subplot_titles=[\"subsample\", \"min_child_weight\", \"max_depth\", \"lambda\",\n",
    "                                    \"gamma\", \"eta\", \"colsample_bytree\", \"alpha\"])\n",
    "fig.add_trace(\n",
    "    go.Box(x=grid_search_scores_xgboost[\"param_subsample\"], y=grid_search_scores_xgboost[\"mean_score\"],\n",
    "           name=\"subsample\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Box(x=grid_search_scores_xgboost[\"param_min_child_weight\"], y=grid_search_scores_xgboost[\"mean_score\"],\n",
    "           name=\"min_child_weight\"),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Box(x=grid_search_scores_xgboost[\"param_max_depth\"], y=grid_search_scores_xgboost[\"mean_score\"],\n",
    "           name=\"max_depth\"),\n",
    "    row=1, col=3\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=grid_search_scores_xgboost[\"param_lambda\"], y=grid_search_scores_xgboost[\"mean_score\"], mode='markers',\n",
    "               name=\"lambda\"),\n",
    "    row=1, col=4\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Box(x=grid_search_scores_xgboost[\"param_gamma\"], y=grid_search_scores_xgboost[\"mean_score\"], name=\"gamma\"),\n",
    "    row=1, col=5\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Box(x=grid_search_scores_xgboost[\"param_eta\"], y=grid_search_scores_xgboost[\"mean_score\"], name=\"eta\"),\n",
    "    row=1, col=6\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Box(x=grid_search_scores_xgboost[\"colsample_bytrees\"], y=grid_search_scores_xgboost[\"mean_score\"],\n",
    "           name=\"colsample_bytree\"),\n",
    "    row=1, col=7\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Box(x=grid_search_scores_xgboost[\"param_alpha\"], y=grid_search_scores_xgboost[\"mean_score\"], name=\"alpha\"),\n",
    "    row=1, col=8\n",
    ")\n",
    "\n",
    "fig.update_layout(height=600, width=2000, title_text=\"Hyperparameter for Target Variable R\\u00b2\")\n",
    "plotly.offline.plot(fig, filename='data/xgboost_grid_search_results.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute testrun 1200 times\n",
    "mean_result = []\n",
    "lm = xgb.XGBRegressor(predictor=\"auto\", nthread=-1, verbosity=0, subsample=0.6,\n",
    "                      min_child_weight=12,\n",
    "                      max_depth=15, reg_lambda=0.04, gamma=0.4, eta=0.1, colsample_bytree=0.7, reg_alpha=1.0)\n",
    "\n",
    "predicted = []\n",
    "true_vals = []\n",
    "feature_imp = dict()\n",
    "for i in tqdm(range(1200)):\n",
    "    cv_result = []\n",
    "    indices = []\n",
    "    s_split = ShuffleSplit(n_splits=5, test_size=0.2, train_size=0.8)\n",
    "    for train_index, test_index in s_split.split(x_data):\n",
    "        indices.append([train_index, test_index])\n",
    "        X_train, X_test = x_data.iloc[train_index], x_data.iloc[test_index]\n",
    "        y_train, y_test = y_data.iloc[train_index], y_data.iloc[test_index]\n",
    "        t1 = time()\n",
    "        lm.fit(X_train, y_train)\n",
    "\n",
    "        coeff = np.abs(lm.feature_importances_)\n",
    "        rel_func = lambda x: x / np.sum(coeff)\n",
    "        coeff = rel_func(coeff)\n",
    "\n",
    "        for counter, column in enumerate(x_data.columns):\n",
    "            if column in feature_imp.keys():\n",
    "                feature_imp[column].append(coeff[counter])\n",
    "            else:\n",
    "                feature_imp.update({column: [coeff[counter]]})\n",
    "\n",
    "        y_pred = lm.predict(X_test)\n",
    "        t2 = time()\n",
    "        predicted.append(y_pred.tolist())\n",
    "        true_vals.append(y_test[\"new_deaths_smoothed\"].tolist())\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        cv_result.append([r2, mse, rmse, mae, mape, t2 - t1])\n",
    "    means = list(np.mean(np.array(cv_result), axis=0))\n",
    "    mean_result.append(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Feature Importances and Export results\n",
    "for key, value in feature_imp.items():\n",
    "    feature_imp[key] = np.mean(feature_imp[key])\n",
    "imp_coef = pd.Series(feature_imp)\n",
    "imp_coef = pd.DataFrame(imp_coef).reset_index()\n",
    "imp_coef.columns = [\"Feature\", \"Value\"]\n",
    "imp_coef = imp_coef.sort_values(by=\"Value\", ascending=False)\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=imp_coef)\n",
    "plt.title('Relative XGBoost Feature Importance (mean over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('xgboost_importances-01.png', dpi=200)\n",
    "plt.show()\n",
    "\n",
    "pd.DataFrame(mean_result, columns=[\"R2\", \"MSE\", \"RMSE\", \"MAE\", \"MAPE\", \"Execution Time\"]).to_excel(\n",
    "    \"data/xgboost_cv_run.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Prediction Interval\n",
    "predicted = list(chain.from_iterable(predicted))\n",
    "true_vals = list(chain.from_iterable(true_vals))\n",
    "\n",
    "regression_res_collected = dict()\n",
    "\n",
    "for counter, true_val in enumerate(true_vals):\n",
    "    if true_val in regression_res_collected.keys():\n",
    "        regression_res_collected[true_val].append(predicted[counter])\n",
    "    else:\n",
    "        regression_res_collected.update({true_val: [predicted[counter]]})\n",
    "\n",
    "regression_res_collected = dict(sorted(regression_res_collected.items()))\n",
    "\n",
    "for key, value in regression_res_collected.items():\n",
    "    regression_res_collected[key] = [min(regression_res_collected[key]), max(regression_res_collected[key])]\n",
    "\n",
    "max_pred = []\n",
    "min_pred = []\n",
    "for key, value in regression_res_collected.items():\n",
    "    max_pred.append(value[1])\n",
    "    min_pred.append(value[0])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "real_vals = list(regression_res_collected.keys())\n",
    "# ax.fill(np.concatenate([real_vals, real_vals[::-1]]), np.concatenate([min_pred, max_pred[::-1]]), alpha=.1, fc='b',\n",
    "#         ec='None', label='Prediction Interval')\n",
    "ax.fill_between(real_vals, min_pred, max_pred, alpha=1.0, interpolate=True, color=\"red\", label='Prediction Interval')\n",
    "ax.plot([min(true_vals), max(true_vals)], [min(true_vals), max(true_vals)], color=\"blue\", linestyle='--', lw=4,\n",
    "        label=\"Ideal Prediction\")\n",
    "ax.set_xlabel(\"Real new_deaths_smoothed\")\n",
    "ax.set_ylabel(\"Predicted new_deaths_smoothed\")\n",
    "fig.suptitle('XGBoost Regression', fontsize=16)\n",
    "plt.legend(loc=\"upper left\", frameon=False)\n",
    "plt.savefig(\"data/xgboost_cv_results.png\", dpi=250)\n",
    "plt.show()"
   ]
  }
 ]
}